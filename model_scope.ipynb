{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/luthando/miniconda3/envs/vgen/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-03-04 17:59:24,686 - modelscope - INFO - PyTorch version 2.2.0 Found.\n",
      "2024-03-04 17:59:24,687 - modelscope - INFO - Loading ast index from /home/luthando/.cache/modelscope/ast_indexer\n",
      "2024-03-04 17:59:24,700 - modelscope - INFO - Loading done! Current index file version is 1.4.2, with md5 37fd16355b0d36a16ba1689edf1d5489 and a total number of 842 components indexed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No module named 'tensorflow'\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope.outputs import OutputKeys\n",
    "import pathlib\n",
    "\n",
    "model_dir = pathlib.Path('weights')\n",
    "# snapshot_download('damo-vilab/modelscope-damo-text-to-video-synthesis',\n",
    "#                    repo_type='model', local_dir=model_dir)\n",
    "# # snapshot_download('damo-vilab/text-to-video-ms-1.7b',\n",
    "# #                    repo_type='model', local_dir=model_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 17:59:33,433 - modelscope - INFO - initiate model from weights\n",
      "2024-03-04 17:59:33,433 - modelscope - INFO - initiate model from location weights.\n",
      "2024-03-04 17:59:33,434 - modelscope - INFO - initialize model from weights\n",
      "2024-03-04 17:59:53,579 - modelscope - WARNING - No preprocessor field found in cfg.\n",
      "WARNING:modelscope:No preprocessor field found in cfg.\n",
      "2024-03-04 17:59:53,580 - modelscope - WARNING - No val key and type key found in preprocessor domain of configuration.json file.\n",
      "WARNING:modelscope:No val key and type key found in preprocessor domain of configuration.json file.\n",
      "2024-03-04 17:59:53,581 - modelscope - WARNING - Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'weights'}. trying to build by task and model information.\n",
      "WARNING:modelscope:Cannot find available config to build preprocessor at mode inference, current config: {'model_dir': 'weights'}. trying to build by task and model information.\n",
      "2024-03-04 17:59:53,582 - modelscope - WARNING - No preprocessor key ('latent-text-to-video-synthesis', 'text-to-video-synthesis') found in PREPROCESSOR_MAP, skip building preprocessor.\n",
      "WARNING:modelscope:No preprocessor key ('latent-text-to-video-synthesis', 'text-to-video-synthesis') found in PREPROCESSOR_MAP, skip building preprocessor.\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline('text-to-video-synthesis', model_dir.as_posix())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-04 17:59:58,936 - modelscope - WARNING - task text-to-video-synthesis input definition is missing\n",
      "WARNING:modelscope:task text-to-video-synthesis input definition is missing\n",
      "2024-03-04 18:00:15,282 - modelscope - WARNING - task text-to-video-synthesis output keys are missing\n",
      "WARNING:modelscope:task text-to-video-synthesis output keys are missing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output_video_path: /tmp/tmpfy8oqcil.mp4 moved to ->  /home/luthando/Desktop/i2vgen-xl/outputs/tmp/tmpfy8oqcil.mp4\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_text = {\n",
    "    'text': 'A person standing walking on a tar road on bridge.',\n",
    "}\n",
    "output_video_path = pipe(test_text,)[OutputKeys.OUTPUT_VIDEO]\n",
    "!mv '{output_video_path}' '/home/luthando/Desktop/i2vgen-xl/outputs{output_video_path}'\n",
    "print('output_video_path:', output_video_path, \"moved to -> \", f'/home/luthando/Desktop/i2vgen-xl/outputs{output_video_path}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vgen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

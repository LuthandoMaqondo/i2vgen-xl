{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "try:\n",
    "    from google.colab import drive\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    WORKING_DIR = '.'\n",
    "    IN_COLAB = False\n",
    "if IN_COLAB:\n",
    "    WORKING_DIR = '/content/drive/MyDrive/Colab Notebooks'\n",
    "    # Mount drive in order access Google drive\n",
    "    drive.mount('/content/drive',  force_remount=True)\n",
    "    \n",
    "# if IN_COLAB:\n",
    "#     sys.path.insert(0, WORKING_DIR)\n",
    "# else:\n",
    "#     # The actual code is one level higher in folder depth/structure, so we're elevating this notebook.\n",
    "#     sys.path.insert(0,f\".{WORKING_DIR}/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting ./configs/t2v_train_custom.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile ./configs/t2v_train_custom.yaml\n",
    "\n",
    "TASK_TYPE: train_t2v_entrance\n",
    "ENABLE: true\n",
    "use_ema: false\n",
    "num_workers: 6\n",
    "frame_lens: [1, 16, 16, 16, 16, 32, 32, 32]\n",
    "sample_fps: [1,  8,  16, 16, 16, 8,  16, 16]\n",
    "resolution: [448, 256]\n",
    "vit_resolution: [224, 224]\n",
    "vid_dataset: {\n",
    "    'type': 'VideoDataset',\n",
    "    'data_list': ['data/vid_list_custom.txt', ],\n",
    "    'data_dir_list': [ \"~/.cache/datasets/Appimate/train\", ],\n",
    "    'vit_resolution': [224, 224],\n",
    "    'resolution': [448, 256],\n",
    "    'get_first_frame': True,\n",
    "    'max_words': 1000,\n",
    "}\n",
    "embedder: {\n",
    "    'type': 'FrozenOpenCLIPTtxtVisualEmbedder',\n",
    "    'layer': 'penultimate',\n",
    "    'vit_resolution': [224, 224],\n",
    "    'pretrained': 'models/open_clip_pytorch_model.bin'\n",
    "}\n",
    "UNet: {\n",
    "    'type': 'UNetSD_T2VBase',\n",
    "    'in_dim': 4,\n",
    "    'y_dim': 1024,\n",
    "    'upper_len': 128,\n",
    "    'context_dim': 1024,\n",
    "    'out_dim': 4,\n",
    "    'dim_mult': [1, 2, 4, 4],\n",
    "    'num_heads': 8,\n",
    "    'default_fps': 8,\n",
    "    'head_dim': 64,\n",
    "    'num_res_blocks': 2,\n",
    "    'dropout': 0.1,\n",
    "    'misc_dropout': 0.4,\n",
    "    'temporal_attention': True,\n",
    "    'temporal_attn_times': 1,\n",
    "    'use_checkpoint': True,\n",
    "    'use_fps_condition': False,\n",
    "    'use_sim_mask': False\n",
    "}\n",
    "Diffusion: {\n",
    "    'type': 'DiffusionDDIM',\n",
    "    'schedule': 'cosine', # cosine\n",
    "    'schedule_param': {\n",
    "        'num_timesteps': 1000,\n",
    "        'cosine_s': 0.008,\n",
    "        'zero_terminal_snr': True,\n",
    "    },\n",
    "    'mean_type': 'v',\n",
    "    'loss_type': 'mse',\n",
    "    'var_type': 'fixed_small',\n",
    "    'rescale_timesteps': False,\n",
    "    'noise_strength': 0.1\n",
    "}\n",
    "batch_sizes: {\n",
    "    \"1\": 32,\n",
    "    \"4\": 8,\n",
    "    \"8\": 4,\n",
    "    \"16\": 4,\n",
    "    \"32\": 2\n",
    "}\n",
    "visual_train: {\n",
    "    'type': 'VisualTrainTextImageToVideo',\n",
    "    'partial_keys': [\n",
    "        ['y', 'fps'],\n",
    "    ],\n",
    "    'use_offset_noise': False,\n",
    "    'guide_scale': 9.0, \n",
    "}\n",
    "\n",
    "Pretrain: {\n",
    "    'type': pretrain_specific_strategies,\n",
    "    'fix_weight': False,\n",
    "    'grad_scale': 0.5,\n",
    "    'resume_checkpoint': 'workspace/model_bk/model_scope_0267000.pth',\n",
    "    'sd_keys_path': 'data/stable_diffusion_image_key_temporal_attention_x1.json',\n",
    "}\n",
    "\n",
    "chunk_size: 4\n",
    "decoder_bs: 4\n",
    "lr: 0.00003\n",
    "\n",
    "noise_strength: 0.1\n",
    "# classifier-free guidance\n",
    "p_zero: 0.1\n",
    "guide_scale: 3.0\n",
    "num_steps: 1000000\n",
    "\n",
    "use_zero_infer: True\n",
    "viz_interval: 5        # 200\n",
    "save_ckp_interval: 50   # 500\n",
    "\n",
    "# Log\n",
    "log_dir: \"workspace/experiments\"\n",
    "log_interval: 1\n",
    "seed: 8888"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessing STARTED!\n",
      "Data preprocessing DONE: 34 text prompts -> 34 videos\n"
     ]
    }
   ],
   "source": [
    "!python preprocess.py \\\n",
    "    --json_file_path /Users/luthandomaqondo/.cache/datasets/Appimate/dataset.json \\\n",
    "    --output_dir /Users/luthandomaqondo/.cache/datasets/Appimate/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/luthandomaqondo/Development/Python/i2vgen-xl/train_net.py\", line 14, in <module>\n",
      "    from tools import *\n",
      "  File \"/Users/luthandomaqondo/Development/Python/i2vgen-xl/tools/__init__.py\", line 3, in <module>\n",
      "    from .modules import *\n",
      "  File \"/Users/luthandomaqondo/Development/Python/i2vgen-xl/tools/modules/__init__.py\", line 1, in <module>\n",
      "    from .clip_embedder import FrozenOpenCLIPEmbedder\n",
      "  File \"/Users/luthandomaqondo/Development/Python/i2vgen-xl/tools/modules/clip_embedder.py\", line 4, in <module>\n",
      "    import open_clip\n",
      "ModuleNotFoundError: No module named 'open_clip'\n"
     ]
    }
   ],
   "source": [
    "!python train_net.py --cfg configs/t2v_train.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
